from airflow import DAG
from airflow.operators.http_operator import SimpleHttpOperator
from airflow.sensors.http_sensor import HttpSensor
from airflow.sensors.time_delta import TimeDeltaSensor
from airflow.utils.dates import days_ago
from datetime import timedelta
from airflow.providers.slack.notifications.slack import send_slack_notification

import json


{% for dag_ in dag %}
dag = DAG(
    "{{ dag_.dag_id }}",
    schedule_interval="{{ dag_.schedule_interval }}",
    start_date=days_ago(1),
    catchup={{ dag_.catchup or False }},
)
{% endfor %}

{% set delay_durations = data_seconds %}

{% for operator in operators %}
# Define the HTTP operator
http_task_{{ loop.index }} = SimpleHttpOperator(
    task_id="{{ operator.task_id }}",
    http_conn_id="{{ operator.http_conn_id }}",
    endpoint="{{ operator.endpoint }}",
    method="{{ operator.method }}",
    headers={{ operator.headers | tojson }},  # Assuming headers is a dictionary, convert it to JSON
    data=json.dumps({{ operator.data}}),
    log_response={{ operator.log_response }},
    dag=dag,
    on_failure_callback=[
        send_slack_notification(
            text="The task {{ operator.task_id }} for failed",
            channel="#tech-notifications",
            username="airflow",
        )
    ],
)

# Set up task dependencies with dynamic delay durations
{% if loop.index|string in delay_durations %}
{# Add delay sensor between tasks #}
delay_task_{{ loop.index }} = TimeDeltaSensor(
    task_id='delay_task_{{ loop.index }}',
    delta=timedelta(seconds=delay_durations[{{loop.index}}]),  # Use dynamic delay durations from the dictionary
    mode='reschedule',
    dag=dag,
)

http_task_{{ loop.index - 1 }} >> delay_task_{{ loop.index }} >> http_task_{{ loop.index }}
{% else %}
http_task_{{ loop.index - 1 }} >> http_task_{{ loop.index }}
{% endif %}

{% endfor %}
